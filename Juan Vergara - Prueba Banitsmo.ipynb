{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Abrir y leer el archivo README.md para revisar su contenido\nwith open('README.md', 'r') as file:\n    readme_content = file.read()\n\nreadme_content[:2000]  # Mostrar una parte inicial del contenido para revisión",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'# Prueba para analisis de datos\\n\\nPrueba utilizada para aplicar a las plazas de analisis de datos (Entry-level, Junior, y lider)\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# Importación de bibliotecas necesarias\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# 1. Cargar y explorar los datos\n# Cargar el conjunto de datos proporcionado\ndatos_originales = pd.read_csv('default_dataset.csv', sep=',')\n\n# Explorar la estructura y calidad de los datos\nprint(\"Información general del dataset:\")\nprint(datos_originales.info())  # Verificación de tipos de datos y valores nulos\nprint(\"\\nEstadísticas descriptivas:\")\nprint(datos_originales.describe())  # Estadísticas descriptivas iniciales\n\n# 2. Limpieza de Datos\n# Eliminar filas con más del 50% de datos faltantes\ndatos = datos_originales.dropna(thresh=int(0.5 * datos_originales.shape[1]))\n\n# Imputar valores faltantes\ndatos.fillna(datos.median(), inplace=True)\ndatos.fillna(datos.mode().iloc[0], inplace=True)\n\n# 3. Selección de Variables y Preprocesamiento\n# Selección de características más relevantes\ncorrelaciones = datos.corr()\nvariables_seleccionadas = correlaciones['default'].sort_values(ascending=False).index[:10]\nX = datos[variables_seleccionadas].drop(columns=['default', 'ID'])\ny = datos['default']\n\n# Normalización de las variables numéricas\ntransformador = StandardScaler()\nX_normalizado = transformador.fit_transform(X)\n\n# 4. Entrenamiento del Modelo\n# Entrenamiento de un modelo Random Forest\nmodelo = RandomForestClassifier(random_state=42)\nmodelo.fit(X_normalizado, y)\n\n# 5. Generación de Predicciones y Clasificación en Grupos de Riesgo\n# Obtener las probabilidades predichas\nprobabilidades_predichas = modelo.predict_proba(X_normalizado)[:, 1]\n\n# Clasificación de los clientes en grupos de riesgo\n# Definir los límites de los grupos de riesgo\nlimites_grupos_riesgo = [0, 0.01, 0.015, 0.03, 0.045, 0.08, 0.15, 0.30, 1]\nnombres_grupos_riesgo = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8']\ngrupos_riesgo = pd.cut(probabilidades_predichas, bins=limites_grupos_riesgo, labels=nombres_grupos_riesgo)\n\n# 6. Generación del Archivo de Resultados\n# Crear el DataFrame de resultados y guardarlo en un archivo CSV\nresultados = pd.DataFrame({'ID': datos['ID'], 'Grupo de Riesgo': grupos_riesgo})\nresultados.to_csv('clasificacion_predicciones.csv', index=False)\nprint(\"\\nArchivo 'clasificacion_predicciones.csv' generado con éxito.\")\n\n# 7. Recomendaciones y Mejoras\n# Comentamos posibles mejoras y recomendaciones\n\n# 7.1. Optimización Adicional\n# Se recomienda ajustar los hiperparámetros utilizando Random Search o Bayesian Optimization\n# para mejorar la precisión y generalización del modelo.\n\n# 7.2. Inclusión de Nuevas Variables\n# Considerar la inclusión de variables adicionales, como datos socioeconómicos o más detalles\n# sobre el historial crediticio, para aumentar la capacidad predictiva del modelo.\n\n# 7.3. Implementación de un API\n# Para obtener puntos adicionales, se sugiere desarrollar un API en Python utilizando Flask o FastAPI,\n# que permita exponer el modelo para su consumo en tiempo real.\n\n\n\n# ----------------------------------------------------------------------------------------------------------------------------------------#\n# 8. Comparación con los datos de 2019 (Código Comentado)\n# Este código está comentado ya que requiere los datos de 2019 para ejecutarse.\n\n# # Cargar los datos de febrero de 2019\n# datos_febrero = pd.read_csv('ruta_a_tu_archivo_febrero.csv', sep=',')\n\n# # Preprocesamiento similar al conjunto de entrenamiento\n# X_febrero = escalador.transform(datos_febrero.drop(columns=['ID']))\n# y_probabilidad_febrero = modelo.predict_proba(X_febrero)[:, 1]\n\n# # Clasificación en grupos de riesgo\n# grupos_riesgo_febrero = pd.cut(y_probabilidad_febrero, bins=[0, 0.01, 0.015, 0.03, 0.045, 0.08, 0.15, 0.30, 1],\n#                               labels=['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8'])\n\n# # Generación del archivo CSV para febrero 2019\n# resultado_febrero = pd.DataFrame({'ID': datos_febrero['ID'], 'Grupo de Riesgo': grupos_riesgo_febrero})\n# resultado_febrero.to_csv('clasificacion_febrero_2019.csv', index=False)\n# print(\"\\nArchivo 'clasificacion_febrero_2019.csv' generado con éxito.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Información general del dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 27999 entries, 0 to 27998\nData columns (total 25 columns):\n #   Column     Non-Null Count  Dtype\n---  ------     --------------  -----\n 0   ID         27999 non-null  int64\n 1   LIMIT_BAL  27999 non-null  int64\n 2   SEX        27999 non-null  int64\n 3   EDUCATION  27999 non-null  int64\n 4   MARRIAGE   27999 non-null  int64\n 5   AGE        27999 non-null  int64\n 6   PAY_0      27999 non-null  int64\n 7   PAY_2      27999 non-null  int64\n 8   PAY_3      27999 non-null  int64\n 9   PAY_4      27999 non-null  int64\n 10  PAY_5      27999 non-null  int64\n 11  PAY_6      27999 non-null  int64\n 12  BILL_AMT1  27999 non-null  int64\n 13  BILL_AMT2  27999 non-null  int64\n 14  BILL_AMT3  27999 non-null  int64\n 15  BILL_AMT4  27999 non-null  int64\n 16  BILL_AMT5  27999 non-null  int64\n 17  BILL_AMT6  27999 non-null  int64\n 18  PAY_AMT1   27999 non-null  int64\n 19  PAY_AMT2   27999 non-null  int64\n 20  PAY_AMT3   27999 non-null  int64\n 21  PAY_AMT4   27999 non-null  int64\n 22  PAY_AMT5   27999 non-null  int64\n 23  PAY_AMT6   27999 non-null  int64\n 24  default    27999 non-null  int64\ndtypes: int64(25)\nmemory usage: 5.3 MB\nNone\n\nEstadísticas descriptivas:\n                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\ncount  27999.000000    27999.000000  27999.000000  27999.000000  27999.000000   \nmean   15749.304368   169647.833137      1.607522      1.853888      1.552484   \nstd     8452.091410   130240.416104      0.488311      0.795310      0.521850   \nmin        3.000000    10000.000000      1.000000      0.000000      0.000000   \n25%     8999.500000    60000.000000      1.000000      1.000000      1.000000   \n50%    15999.000000   140000.000000      2.000000      2.000000      2.000000   \n75%    22998.500000   240000.000000      2.000000      2.000000      2.000000   \nmax    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n\n                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\ncount  27999.000000  27999.000000  27999.000000  27999.000000  27999.000000   \nmean      35.484696     -0.063324     -0.169327     -0.201900     -0.248009   \nstd        9.168462      1.088628      1.162094      1.158822      1.139461   \nmin       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n75%       41.000000      0.000000      0.000000      0.000000      0.000000   \nmax       79.000000      8.000000      8.000000      8.000000      8.000000   \n\n       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\ncount  ...   27999.000000   27999.000000   27999.000000   27999.000000   \nmean   ...   43501.129397   40427.848780   38988.426658    5823.589878   \nstd    ...   64547.035637   60932.675754   59691.059489   16926.065931   \nmin    ... -170000.000000  -81334.000000 -209051.000000       0.000000   \n25%    ...    2373.000000    1809.000000    1278.000000    1000.000000   \n50%    ...   19097.000000   18106.000000   17021.000000    2184.000000   \n75%    ...   55154.500000   50437.500000   49380.000000    5100.000000   \nmax    ...  891586.000000  927171.000000  961664.000000  873552.000000   \n\n           PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\ncount  2.799900e+04   27999.000000   27999.000000   27999.000000   \nmean   6.107637e+03    5383.826137    4951.663381    4878.592700   \nstd    2.362333e+04   17997.627313   16023.404493   15329.242967   \nmin    0.000000e+00       0.000000       0.000000       0.000000   \n25%    1.000000e+03     457.000000     316.000000     298.500000   \n50%    2.078000e+03    1917.000000    1520.000000    1548.000000   \n75%    5.000000e+03    4730.000000    4162.000000    4181.500000   \nmax    1.684259e+06  896040.000000  621000.000000  426529.000000   \n\n            PAY_AMT6       default  \ncount   27999.000000  27999.000000  \nmean     5342.790350      0.165613  \nstd     17990.023991      0.371740  \nmin         0.000000      0.000000  \n25%       188.000000      0.000000  \n50%      1500.000000      0.000000  \n75%      4133.500000      0.000000  \nmax    528666.000000      1.000000  \n\n[8 rows x 25 columns]\n\nArchivo 'clasificacion_predicciones.csv' generado con éxito.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    }
  ]
}